{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3733de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "import cv2\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80039653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sam(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Segment Anything Model\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_l\"\n",
    "CHECKPOINT_PATH=\"/Users/nirwantandukar/Documents/trial_BZea/sam_vit_l_0b3195.pth\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b64d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Mask (Instance Segmentation) Generation with SAM\n",
    "# segmentation - [np.ndarray] - the mask with (W, H) shape, and bool type, where W and H are the width and height \n",
    "#of the original image, respectively\n",
    "#area - [int] - the area of the mask in pixels\n",
    "#bbox - [List[int]] - the boundary box detection in xywh format\n",
    "#predicted_iou - [float] - the model's own prediction for the quality of the mask\n",
    "#point_coords - [List[List[float]]] - the sampled input point that generated this mask\n",
    "#stability_score - [float] - an additional measure of mask quality\n",
    "#crop_box - List[int] - the crop of the image used to generate this mask in xywh format\n",
    "\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "IMAGE_PATH = \"/Users/nirwantandukar/Documents/trial_BZea/71267_Leaf_AngleAuricle_1_2023-07-28-05-58-27.jpg\"\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "result = mask_generator.generate(image_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f489fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the result\n",
    "with open('result.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553f042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result\n",
    "#with open('result.pkl', 'rb') as f:\n",
    "#    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0b3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each mask in the result\n",
    "for i, mask_info in enumerate(result):\n",
    "    mask = mask_info['segmentation']\n",
    "    \n",
    "    # Convert boolean mask to uint8\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    \n",
    "    # Display the mask\n",
    "    cv2.imshow(f'Mask {i+1}', mask)\n",
    "    \n",
    "    # Save the mask to a file\n",
    "    cv2.imwrite(f'mask_{i+1}.png', mask)\n",
    "\n",
    "# Wait for a key press and then close the image windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316ac430",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06bf550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for drawing bounding box\n",
    "drawing = False\n",
    "top_left_pt, bottom_right_pt = None, None\n",
    "\n",
    "# Mouse callback function to draw bounding box\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global drawing, top_left_pt, bottom_right_pt\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        top_left_pt = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        bottom_right_pt = (x, y)\n",
    "        cv2.rectangle(image_bgr, top_left_pt, bottom_right_pt, (0, 255, 0), 2)\n",
    "        cv2.imshow('Draw Bounding Box', image_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11ba066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "IMAGE_PATH = \"/Users/nirwantandukar/Documents/trial_BZea/71267_Leaf_AngleAuricle_1_2023-07-28-05-58-27.jpg\"\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "cv2.namedWindow('Draw Bounding Box')\n",
    "cv2.setMouseCallback('Draw Bounding Box', draw_rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image and wait for the bounding box to be drawn\n",
    "cv2.imshow('Draw Bounding Box', image_bgr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Crop the image to the bounding box\n",
    "if top_left_pt and bottom_right_pt:\n",
    "    cropped_image = image_bgr[top_left_pt[1]:bottom_right_pt[1], top_left_pt[0]:bottom_right_pt[0]]\n",
    "    cropped_image_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Generate the mask for the cropped area\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    result = mask_generator.generate(cropped_image_rgb)\n",
    "\n",
    "    # Save the result variable to a file\n",
    "    with open('result_cropped.pkl', 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "\n",
    "    # Display and save the generated masks\n",
    "    for i, mask_info in enumerate(result):\n",
    "        mask = mask_info['segmentation']\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        cv2.imshow(f'Cropped Mask {i+1}', mask)\n",
    "        cv2.imwrite(f'cropped_mask_{i+1}.png', mask)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fa225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "IMAGE_PATH = \"/Users/nirwantandukar/Documents/trial_BZea/71267_Leaf_AngleAuricle_1_2023-07-28-05-58-27.jpg\"\n",
    "\n",
    "# Initialize variables for drawing bounding box\n",
    "drawing = False\n",
    "top_left_pt, bottom_right_pt = None, None\n",
    "\n",
    "# Mouse callback function to draw bounding box\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global drawing, top_left_pt, bottom_right_pt\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        top_left_pt = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        bottom_right_pt = (x, y)\n",
    "        cv2.rectangle(image_bgr, top_left_pt, bottom_right_pt, (0, 255, 0), 2)\n",
    "        cv2.imshow('Draw Bounding Box', image_bgr)\n",
    "\n",
    "# Read the image\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "cv2.namedWindow('Draw Bounding Box')\n",
    "cv2.setMouseCallback('Draw Bounding Box', draw_rectangle)\n",
    "\n",
    "# Show the image and wait for the bounding box to be drawn\n",
    "cv2.imshow('Draw Bounding Box', image_bgr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Crop the image to the bounding box\n",
    "if top_left_pt and bottom_right_pt:\n",
    "    cropped_image = image_bgr[top_left_pt[1]:bottom_right_pt[1], top_left_pt[0]:bottom_right_pt[0]]\n",
    "\n",
    "    # Convert to HSV color space\n",
    "    cropped_hsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define range for green color\n",
    "    lower_green = np.array([35, 50, 50])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "\n",
    "    # Threshold the image to segment green objects\n",
    "    mask_green = cv2.inRange(cropped_hsv, lower_green, upper_green)\n",
    "\n",
    "    # Threshold the image to segment other objects\n",
    "    mask_others = cv2.bitwise_not(mask_green)\n",
    "\n",
    "    # Overlay the masks back onto the original image \n",
    "    for mask, color in zip([mask_green, mask_others], [(0, 255, 0), (0, 0, 255)]):\n",
    "        color_mask = cv2.merge([mask, mask, mask])\n",
    "        color_mask = cv2.bitwise_and(color_mask, np.array(color).reshape((1, 1, 3)))  # Apply the color\n",
    "        x1, y1 = top_left_pt\n",
    "        x2, y2 = bottom_right_pt\n",
    "        image_bgr[y1:y2, x1:x2] = cv2.addWeighted(image_bgr[y1:y2, x1:x2].astype('uint8'), 0.7, color_mask.astype('uint8'), 0.3, 0)\n",
    "\n",
    "    # Display the original image with masks overlaid\n",
    "    cv2.imshow('Original Image with Masks', image_bgr)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818cb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
